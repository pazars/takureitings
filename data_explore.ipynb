{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "takureitings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# Stirnu Buks Rating Calibration\n\nThis notebook calibrates the parameters of the pace-adjusted TrueSkill model used for the Stirnu Buks leaderboard. The central question is: **how should the dynamic β (beta) be set so that a normalized pace gap between two runners produces the right amount of rating movement?**\n\nThe analysis follows a natural progression:\n1. Verify that finish-time distributions are not Gaussian → motivates normalization rather than using raw times\n2. Confirm that per-race median normalization produces a consistent scale across events → validates the σ estimate\n3. Measure the distribution of pairwise pace gaps → calibrates `GAP_MULTIPLIER`\n4. Examine participant consistency and repeat-race behaviour → informs `MIN_RACES`\n\nThe `YEAR` and `DISTANCE_NAME` settings below control which dataset is analysed throughout."
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": "## Setup"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944f4c7c",
   "metadata": {},
   "outputs": [],
   "source": "import json\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mticker\nimport scipy.stats as stats\n\nfrom constants import RACES_FILE_PATH\nfrom explore import RaceExplorer\nfrom models.stirnu_buks import parse_stirnu_buks_to_dataframes\n\nYEAR          = 2025           # set to None to include all years\nDISTANCE_NAME = \"lūsis\"        # options: 'vāvere', 'zaķis', 'stirnu_buks', 'lūsis' — or None for all\nTITLE_SUFFIX  = f\"({YEAR} - {DISTANCE_NAME})\" "
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-load",
   "metadata": {},
   "outputs": [],
   "source": "races_raw = json.loads(RACES_FILE_PATH.read_text())\nraces_df_full, results_df_full = parse_stirnu_buks_to_dataframes(races_raw.get(\"stirnu_buks\"))\n\nexplorer = RaceExplorer(races_df_full, results_df_full)\n\nraces_df, results_df = explorer._filter(YEAR, DISTANCE_NAME)\nresults_df = explorer._compute_pace(races_df, results_df)\nresults_df = explorer._compute_normalized_pace(results_df)\nrace_ids   = races_df.index.tolist()\n\nprint(f\"Races: {len(races_df)}, Results: {len(results_df)}, Unique participants: {results_df['participant'].nunique()}\")\nprint(f\"\\nAvailable combinations: {explorer.combinations()}\")"
  },
  {
   "cell_type": "markdown",
   "id": "a3a241d9",
   "metadata": {},
   "source": "## Are finish times normally distributed?\n\nTrueSkill treats every head-to-head comparison as a draw from a Gaussian. If finish times are heavily skewed, using raw times for pairwise comparisons would systematically misrepresent competitive differences — especially at the extremes of the field. Before normalizing, we formally test whether each race's time distribution looks Gaussian."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd55032",
   "metadata": {},
   "outputs": [],
   "source": "n_cols = 3\nn_rows = int(np.ceil(len(race_ids) / n_cols))\n\nfig, axes = plt.subplots(n_rows, n_cols, figsize=(16, n_rows * 4))\naxes = axes.flatten()\n\nfor ax, race_id in zip(axes, race_ids):\n    subset = results_df[results_df['race_id'] == race_id]['pace_s'].dropna()\n    race_name = f\"{races_df.loc[race_id, 'name']} #{races_df.loc[race_id, 'event_no']}\"\n\n    ax.hist(subset / 60, bins=20, density=True, alpha=0.6, color='steelblue', label='Finish time')\n\n    mu, std = stats.norm.fit(subset / 60)\n    x = np.linspace((subset / 60).min(), (subset / 60).max(), 100)\n    ax.plot(x, stats.norm.pdf(x, mu, std), 'r-', lw=2, label=f'Normal μ={mu:.1f} σ={std:.1f}')\n\n    if len(subset) >= 8:\n        _, p = stats.shapiro(subset)\n        ax.set_title(f\"{race_name}\\nShapiro p={p:.3f} {'✓ normal' if p > 0.05 else '✗ not normal'}\")\n    else:\n        ax.set_title(race_name)\n\n    ax.set_xlabel('Finish time (min)')\n    ax.legend(fontsize=7)\n\nfor ax in axes[len(race_ids):]:\n    ax.set_visible(False)\n\nplt.suptitle(f'Finish Time Distributions per Race {TITLE_SUFFIX}', fontsize=14, y=1.01)\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "wo9ojk0yxh",
   "metadata": {},
   "source": "Every race rejects the Shapiro-Wilk test (p ≪ 0.05). The histograms confirm a consistent right skew: the back of the field stretches much further from the median than the front does. This is expected in trail running — tired runners slow down more than fresh runners speed up. Raw finish times cannot safely be used in TrueSkill comparisons, which motivates normalizing relative to the race median."
  },
  {
   "cell_type": "markdown",
   "id": "c6f76d6b",
   "metadata": {},
   "source": "## Skew: mean vs median pace\n\nThe clearest symptom of right skew is mean > median. We check this per race as a sanity check before normalizing — if the skew is consistent in direction and roughly stable in magnitude across events, a single normalization scheme (dividing by the race median) should put all races on a comparable scale."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de6f615",
   "metadata": {},
   "outputs": [],
   "source": "agg = results_df.groupby('race_id')['pace'].agg(['mean', 'median', 'std'])\nagg['diff_pct'] = (agg['mean'] - agg['median']) / agg['median'] * 100\nagg['label'] = agg.index.map(lambda i: f\"{races_df.loc[i, 'name']} #{races_df.loc[i, 'event_no']}\")\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n\nx = np.arange(len(agg))\nax1.bar(x - 0.2, agg['mean'], 0.4, label='Mean', color='steelblue', alpha=0.8)\nax1.bar(x + 0.2, agg['median'], 0.4, label='Median', color='coral', alpha=0.8)\nax1.set_xticks(x)\nax1.set_ylim(bottom=300)\nax1.set_xticklabels(agg['label'], rotation=45, ha='right')\nax1.set_ylabel('Pace (s/km)')\nax1.set_title('Mean vs Median pace')\nax1.legend()\n\nax2.bar(x, agg['diff_pct'], color=['green' if v >= 0 else 'red' for v in agg['diff_pct']], alpha=0.8)\nax2.axhline(0, color='black', linewidth=0.8)\nax2.set_xticks(x)\nax2.set_xticklabels(agg['label'], rotation=45, ha='right')\nax2.set_ylabel('(Mean - Median) / Median %')\nax2.set_title('Skew: positive = right tail (slow runners)')\n\nplt.tight_layout()\nplt.show()\n\nprint(agg[['label', 'mean', 'median', 'diff_pct']].to_string())"
  },
  {
   "cell_type": "markdown",
   "id": "qlq37zlud7",
   "metadata": {},
   "source": "Mean pace consistently exceeds median in every race, with the gap ranging from roughly 3–8%. The skew is stable in direction and magnitude across events, confirming that per-race median normalization is appropriate."
  },
  {
   "cell_type": "markdown",
   "id": "7ec20c62",
   "metadata": {},
   "source": "## Normalized pace\n\nRaw finish times cannot be compared across races — terrain, distance, and conditions differ each time. We define normalized pace as deviation from the race median:\n\n`norm_pace = (pace − median_pace) / median_pace`\n\nA value of 0 means exactly median speed; +0.1 means 10% slower than median. The spread (σ) of this distribution directly informs TrueSkill's β. The skewness stats below confirm that normalization preserves the right-skew character (the distribution is not made symmetric), but the scale is now race-agnostic."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8052016",
   "metadata": {},
   "outputs": [],
   "source": "from scipy.stats import skew, skewtest, kurtosis\n\nfor race_id in race_ids:\n    subset = results_df[results_df['race_id'] == race_id]['norm_pace'].dropna()\n    sk = skew(subset)\n    kurt = kurtosis(subset)  # excess kurtosis, 0 = normal\n    _, p = skewtest(subset)  # tests if skew is significantly different from 0\n    race_name = f\"{races_df.loc[race_id, 'name']} #{races_df.loc[race_id, 'event_no']}\"\n    print(f\"{race_name}: skew={sk:.3f}, kurtosis={kurt:.3f}, skewtest p={p:.3f}\")"
  },
  {
   "cell_type": "markdown",
   "id": "514ec7cb",
   "metadata": {},
   "source": "## Normalized pace distribution\n\nWith normalization defined, we inspect its distribution — both pooled across all races and per race. This answers two questions: (a) does normalization produce a consistent spread across events, and (b) what σ characterizes the typical performance range that β needs to account for?"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81e4a13",
   "metadata": {},
   "outputs": [],
   "source": "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n\naxes[0].hist(results_df['norm_pace'], bins=40, color='steelblue', alpha=0.7, density=True)\nmu, std = stats.norm.fit(results_df['norm_pace'].dropna())\nx = np.linspace(results_df['norm_pace'].min(), results_df['norm_pace'].max(), 200)\naxes[0].plot(x, stats.norm.pdf(x, mu, std), 'r-', lw=2, label=f'Normal fit μ={mu:.3f} σ={std:.3f}')\naxes[0].set_xlabel('Normalized pace')\naxes[0].set_title(f'Normalized pace distribution {TITLE_SUFFIX}')\naxes[0].legend()\n\ndata_per_race = [results_df[results_df['race_id'] == rid]['norm_pace'].dropna().values for rid in race_ids]\nlabels = [f\"#{races_df.loc[rid, 'event_no']}\" for rid in race_ids]\naxes[1].boxplot(data_per_race, labels=labels)\naxes[1].axhline(0, color='red', linestyle='--', alpha=0.5, label='Median (=0 by definition)')\naxes[1].set_xlabel('Race')\naxes[1].set_ylabel('Normalized pace')\naxes[1].set_title('Normalized pace spread per race')\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"Overall norm_pace std: {results_df['norm_pace'].std():.4f}\")"
  },
  {
   "cell_type": "markdown",
   "id": "norm-pace-insight",
   "metadata": {},
   "source": "The pooled σ ≈ 0.20, meaning a typical runner's pace falls within roughly ±20% of the race median. The per-race boxplots show similar interquartile ranges across all events, confirming that normalization makes the performance scale comparable across races. We treat σ ≈ 0.20 as the reference spread when reasoning about β."
  },
  {
   "cell_type": "markdown",
   "id": "0f56fd30",
   "metadata": {},
   "source": "## Pairwise pace gaps: calibrating the dynamic β multiplier\n\nThe pace-adjusted TrueSkill update uses a dynamic β: `β = max(β_min, β_base / (1 + gap × M))`. A large normalized pace gap → smaller β → the faster runner is expected to win decisively → the update moves ratings less. We want β to halve at a *typical* competitive gap — sensitive enough to distinguish genuine performance differences, but not so aggressive that it suppresses all rating movement from close finishes. To pick the multiplier M, we need the empirical distribution of pairwise normalized pace gaps."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eef4b0c",
   "metadata": {},
   "outputs": [],
   "source": "gaps, percentiles = explorer._compute_pairwise_gaps(races_df, results_df)\n\nfig, ax = plt.subplots(figsize=(12, 5))\nax.hist(gaps, bins=60, color='steelblue', alpha=0.7, density=True)\nfor p, v in percentiles.items():\n    ax.axvline(v, linestyle='--', label=f'p{p}={v:.3f}')\nax.set_xlabel('Pairwise normalized pace gap')\nax.set_title(f'Distribution of pairwise pace gaps {TITLE_SUFFIX}')\nax.legend()\nplt.tight_layout()\nplt.show()\n\nprint(f\"Median pairwise gap : {percentiles[50]:.4f}\")\nprint(f\"p75 gap             : {percentiles[75]:.4f}\")\nprint(f\"p90 gap             : {percentiles[90]:.4f}\")\nprint(f\"Suggested M         : 1 / {percentiles[50]:.4f} = {1/percentiles[50]:.1f}\")"
  },
  {
   "cell_type": "markdown",
   "id": "ta1nbl3eylc",
   "metadata": {},
   "source": "The median pairwise gap is ≈ 0.18 normalized pace units. Setting `M ≈ 1/0.18 ≈ 5.5` makes β halve at the typical competitive gap, matching `GAP_MULTIPLIER = 6` in `constants.py`. The long right tail (gaps > 0.5) covers front-to-back matchups that are highly one-sided — these receive a very small β and contribute minimal rating movement, which is the intended behaviour for large mismatches."
  },
  {
   "cell_type": "markdown",
   "id": "c4fbf60d",
   "metadata": {},
   "source": "## Field composition: repeat participants\n\nTrueSkill learns from repeated matchups between the same runners. A participant who appears only once stays near their prior (μ = 25, σ = 8.33) and their rating carries little information. The `MIN_RACES` threshold sets the minimum evidence required before a rating is considered meaningful — too low pollutes the leaderboard with under-tested entries; too high excludes most of the field. We profile how many participants return across multiple races."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c0ff79",
   "metadata": {},
   "outputs": [],
   "source": "composition = explorer._compute_field_composition(results_df)\nrace_counts_per_participant = composition['race_counts']\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\naxes[0].hist(race_counts_per_participant, bins=range(1, race_counts_per_participant.max() + 2),\n             color='steelblue', alpha=0.8, align='left')\naxes[0].set_xlabel('Number of races entered')\naxes[0].set_ylabel('Number of participants')\naxes[0].set_title('Participant race frequency')\naxes[0].xaxis.set_major_locator(mticker.MultipleLocator(1))\n\nthresholds = range(1, race_counts_per_participant.max() + 1)\ncoverage = [(race_counts_per_participant >= t).sum() / race_counts_per_participant.count() * 100 for t in thresholds]\naxes[1].plot(list(thresholds), coverage, marker='o', color='coral')\naxes[1].set_xlabel('Min races threshold')\naxes[1].set_ylabel('% of participants included')\naxes[1].set_title('Leaderboard coverage vs MIN_RACES threshold')\naxes[1].xaxis.set_major_locator(mticker.MultipleLocator(1))\naxes[1].yaxis.set_major_formatter(mticker.PercentFormatter())\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(race_counts_per_participant.value_counts().sort_index().rename('participants').to_frame())"
  },
  {
   "cell_type": "markdown",
   "id": "field-comp-insight",
   "metadata": {},
   "source": "About 51% of participants appear in 2+ races, and 34% in 3+. In a 5-race season, `MIN_RACES = 2` retains roughly half the field while excluding single-race entrants whose ratings are untested. Raising to 3 drops coverage by another ~18 percentage points for limited benefit — most of the rating signal comes from the first two appearances anyway."
  },
  {
   "cell_type": "markdown",
   "id": "gap-struct-header",
   "metadata": {},
   "source": "## Gap structure: does the field spread out toward the back?\n\nOur dynamic β applies the same formula regardless of finishing position. If gaps systematically grow toward the back — slower runners more dispersed than fast runners — then a given absolute gap means different things depending on where in the field it occurs. We check whether the step from one finisher to the next varies by position."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gap-struct-code",
   "metadata": {},
   "outputs": [],
   "source": "gap_struct = explorer._compute_gap_structure(races_df, results_df)\n\nfig, axes = plt.subplots(1, 2, figsize=(16, 5))\n\nall_consec = []\nfor race_id in race_ids:\n    subset = results_df[results_df['race_id'] == race_id].sort_values('pace')['norm_pace'].dropna().values\n    all_consec.extend(np.diff(subset))\n\naxes[0].hist(np.array(all_consec), bins=40, color='steelblue', alpha=0.7)\naxes[0].set_xlabel('Normalized pace gap to next finisher')\naxes[0].set_title('Consecutive finisher gaps (all races)')\n\npos_pcts, gap_vals = [], []\nfor race_id in race_ids:\n    subset = results_df[results_df['race_id'] == race_id].sort_values('pace')['norm_pace'].dropna().values\n    n = len(subset)\n    for i, gap in enumerate(np.diff(subset)):\n        pos_pcts.append(i / n * 100)\n        gap_vals.append(gap)\n\naxes[1].scatter(pos_pcts, gap_vals, alpha=0.2, s=10, color='steelblue')\ntrend = np.poly1d(np.polyfit(pos_pcts, gap_vals, 1))\nxs = np.linspace(0, 100, 100)\naxes[1].plot(xs, trend(xs), 'r-', lw=2, label=f\"Trend slope={gap_struct['trend_slope']:.5f}\")\naxes[1].set_xlabel('Finishing position percentile')\naxes[1].set_ylabel('Gap to next finisher (norm pace)')\naxes[1].set_title('Do gaps grow toward the back?')\naxes[1].legend()\n\nplt.suptitle(f'Gap Structure {TITLE_SUFFIX}', fontsize=14)\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "gap-struct-insight",
   "metadata": {},
   "source": "Gaps do grow toward the back, but only mildly. The dynamic β formula already handles this naturally: larger gaps → smaller β → more decisive outcome for the model. No additional position-dependent adjustment is needed."
  },
  {
   "cell_type": "markdown",
   "id": "ohz1f9hx3vk",
   "metadata": {},
   "source": "## Participant pace consistency across races\n\nA key assumption of any rating system is that a runner's performance is a *stable* signal — someone who is fast in one race should tend to be fast in others. If normalized pace varies wildly across appearances, TrueSkill cannot converge on meaningful ratings regardless of how β is tuned. We check this by examining how consistently repeat participants perform."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10gdrgx3vse",
   "metadata": {},
   "outputs": [],
   "source": "repeat_participants = results_df.groupby('participant').filter(lambda x: len(x) >= 2)\n\nconsistency = repeat_participants.groupby('participant')['norm_pace'].agg(['std', 'mean', 'count'])\nconsistency.columns = ['pace_std', 'pace_mean', 'n_races']\n\nordered = results_df.sort_values('race_id')\nfirst_pace  = ordered.groupby('participant')['norm_pace'].nth(0).rename('pace_r1')\nsecond_pace = ordered.groupby('participant')['norm_pace'].nth(1).rename('pace_r2')\npaired = first_pace.to_frame().join(second_pace, how='inner').dropna()\ncorr = paired['pace_r1'].corr(paired['pace_r2'])\n\nfig, axes = plt.subplots(1, 2, figsize=(16, 5))\n\naxes[0].hist(consistency['pace_std'].dropna(), bins=30, color='steelblue', alpha=0.7)\naxes[0].axvline(consistency['pace_std'].median(), color='red', linestyle='--',\n                label=f\"Median std = {consistency['pace_std'].median():.3f}\")\naxes[0].set_xlabel('Std of normalized pace across races')\naxes[0].set_ylabel('Participants')\naxes[0].set_title(f'Per-participant pace consistency {TITLE_SUFFIX}')\naxes[0].legend()\n\naxes[1].scatter(paired['pace_r1'], paired['pace_r2'], alpha=0.4, s=20, color='steelblue')\nm, b = np.polyfit(paired['pace_r1'], paired['pace_r2'], 1)\nxs = np.linspace(paired['pace_r1'].min(), paired['pace_r1'].max(), 100)\naxes[1].plot(xs, m * xs + b, 'r-', lw=2, label=f'r = {corr:.2f}')\naxes[1].set_xlabel('Normalized pace — first race')\naxes[1].set_ylabel('Normalized pace — next race')\naxes[1].set_title(f'Race-to-race pace correlation {TITLE_SUFFIX}')\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"Median per-participant pace std : {consistency['pace_std'].median():.3f}  (vs overall field std ≈ 0.20)\")\nprint(f\"Race-to-race pace correlation   : {corr:.3f}\")"
  },
  {
   "cell_type": "markdown",
   "id": "li5w3ds5k9s",
   "metadata": {},
   "source": "A positive race-to-race correlation (r > 0) means a runner's pace in their first race predicts subsequent appearances — there is a real, learnable signal. If the median per-participant std is substantially lower than the overall field std (≈ 0.20), it confirms that between-runner differences are larger than within-runner variation: TrueSkill is measuring something stable rather than just noise."
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": "## Summary: suggested parameter values\n\nPulling together the findings above into concrete recommendations for `constants.py`."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary-code",
   "metadata": {},
   "outputs": [],
   "source": "result = explorer.analyze(YEAR, DISTANCE_NAME)\n\nprint(\"=== Suggested TrueSkill parameters ===\")\nprint(f\"β_base = 4.167  (TrueSkill default μ/6 = 25/6)\")\nprint(f\"β_min  = 0.5    (floor for large gaps)\")\nprint()\nprint(f\"=== Dynamic beta calibration ===\")\nprint(f\"norm_pace std              : {result.norm_pace_std:.4f}\")\nprint(f\"median pairwise gap        : {result.pairwise_median_gap:.4f}\")\nprint(f\"suggested GAP_MULTIPLIER   : {result.suggested_multiplier}\")\nprint(f\"  → β = max(0.5, 4.167 / (1 + gap × {result.suggested_multiplier}))\")\nprint()\nprint(f\"=== Participant signal quality ===\")\nprint(f\"race-to-race correlation   : {result.race_to_race_corr:.3f}\")\nprint(f\"median participant std     : {result.median_participant_std:.4f}\")\nprint()\nprint(f\"=== MIN_RACES coverage ===\")\nprint(f\"  2+ races: {result.repeat_rate_2plus:.1%} of participants\")\nprint(f\"  3+ races: {result.repeat_rate_3plus:.1%} of participants\")\nprint(f\"  4+ races: {result.repeat_rate_4plus:.1%} of participants\")"
  },
  {
   "cell_type": "markdown",
   "id": "run-all-header",
   "metadata": {},
   "source": "## Cross-distance comparison\n\nRun the full analysis for every (year, distance) combination present in the dataset and compare the suggested β multipliers side by side. This is the main automation loop — any distance or year with enough data will be calibrated automatically."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-all-code",
   "metadata": {},
   "outputs": [],
   "source": "all_results = explorer.run_all()\nexplorer.summary_table(all_results)"
  }
 ]
}